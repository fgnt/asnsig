{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Distributed Synchronization for Ad-Hoc Acoustic Sensor Networks\n",
    "### (N. KnÃ¤pper, A. Chinaev \\& G. Enzner)\n",
    "\n",
    "### A demo to the IWAENC 2022 publication \"Distributed Synchronization for Ad-Hoc Acoustic Sensor Networks Using Closed-Loop Double-Cross-Correlation Processing (DXCP)\" written by A. Chinaev and G. Enzner.\n",
    "\n",
    "### For presentation at the Satellite Workshop of DFG research unit Acoustic Sensor Networks (ASN) \\& european training network Service-Oriented, Ubiquitous, Network-Driven Sound (SOUNDS)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from paderbox.io import load_audio\n",
    "from lazy_dataset.database import JsonDatabase\n",
    "\n",
    "import sys\n",
    "sys.path.append('modules/')\n",
    "from demo_utils import *\n",
    "from audio_reader import AudioReader # customized, previously part of asn_testbed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Demo configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_ROOT = 'data/'\n",
    "SIMULATE_ONLINE = True #True: Online sequential; False: Offline simulation on several processor cores\n",
    "CONTROL_INIT_SRO_EST = False #False: Regular SRO Estimation as seen in [1], True: Control initial SRO Estimation (experimental)\n",
    "\n",
    "sig_len_sec = 150\n",
    "ssnr_t_max = sig_len_sec\n",
    "\n",
    "fs_Hz = 16e3\n",
    "frame_len = 2**11\n",
    "testbed_json = DATA_ROOT+'json/testbed.json'\n",
    "json_pos = DATA_ROOT+'json/positions.json'\n",
    "room_model = DATA_ROOT+'room_model.stl'\n",
    "n_frames = int((sig_len_sec*fs_Hz)/frame_len) \n",
    "example_db = JsonDatabase(testbed_json)\n",
    "examples = example_db.get_dataset('examples')\n",
    "ex_id = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set, verify and plot the network topology"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nodes_levels = [\n",
    "    [['node_0', 'node_1', 'node_9']],\n",
    "    [['node_9', 'node_10', 'node_11']]\n",
    "]\n",
    "#nodes_levels = get_example_topology('ROT') # 'SOT', 'POT' or 'ROT'\n",
    "\n",
    "if verify_topology(nodes_levels, examples[ex_id]['nodes'].keys()):\n",
    "    nodes_select = get_unique_node_list(nodes_levels)\n",
    "    n_async_nodes = len(nodes_select)-1\n",
    "    plot_positions_and_topology(examples[ex_id], room_model, sig_len_sec, nodes_levels)\n",
    "else: # force stop\n",
    "    raise UserWarning('Invalid topology description.')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Audio- and Metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LOAD AUDIO\n",
    "audio_reader = AudioReader(data_root=DATA_ROOT, block_length=frame_len, block_shift=frame_len, node_ids=nodes_select, mic_ids='mic_0')\n",
    "examples = examples.map(audio_reader)\n",
    "\n",
    "frame_len = np.shape(examples[ex_id]['audio'][nodes_select[0]]['mic_0'])[1]\n",
    "n_frames_max = min([np.shape(examples[ex_id]['audio'][node_id]['mic_0'])[0] for node_id in nodes_select])\n",
    "n_frames = int((sig_len_sec*fs_Hz)/frame_len) \n",
    "if n_frames > n_frames_max:\n",
    "    n_frames = n_frames_max\n",
    "    sig_len_prev = sig_len_sec\n",
    "    sig_len_sec = n_frames*frame_len/fs_Hz\n",
    "    print('Warning: Audio signals too short for desired simulation length of ', str(sig_len_prev), 's. \\nReduced simulation length to ', str(sig_len_sec), 's')\n",
    "signals = np.stack(tuple(examples[ex_id]['audio'][node]['mic_0'][:n_frames,:] for node in nodes_select), axis=2)\n",
    "\n",
    "# GET GROUND TRUTH SRO (AND STO)\n",
    "SRO_true = np.zeros((n_async_nodes))\n",
    "STO_true = np.zeros((n_async_nodes))\n",
    "for i in range(1, len(nodes_select)):\n",
    "    SRO_true[i-1] = examples[ex_id]['nodes'][nodes_select[i]]['sro'] - examples[ex_id]['nodes'][nodes_select[0]]['sro']\n",
    "    STO_true[i-1] = examples[ex_id]['nodes'][nodes_select[i]]['sto'] - examples[ex_id]['nodes'][nodes_select[0]]['sto'] \n",
    "\n",
    "# GET PLACEHOLDER ORACLE ACS\n",
    "oracle_acs = get_oracle_acs(examples[ex_id], sig_len_sec, len_dxcpphat_est=n_frames, delay=12.8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Source activity and scene diary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_pos_hist(examples[ex_id]['src_diary'], sig_len_sec)\n",
    "plot_scene_diary(examples[ex_id]['scene_diary'], sig_len_sec)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Run SRO estimation (by using closed-loop DXCP) and signal synchronization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if SIMULATE_ONLINE:\n",
    "    print('Running online sequential simulation...')\n",
    "    signals_synced, SRO_est, dSRO_est = run_simulation_online(nodes_levels, signals, oracle_acs, CONTROL_INIT_SRO_EST)\n",
    "\n",
    "else:\n",
    "    print('Running offline multicore simulation...')\n",
    "    signals_synced, SRO_est, dSRO_est = run_simulation_parallel(nodes_levels, signals, oracle_acs, CONTROL_INIT_SRO_EST)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Evaluation Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get synchronous signals (for comparison to synchronized signals)\n",
    "signals_sync = np.zeros_like(signals)\n",
    "for i in range(n_async_nodes+1):\n",
    "    signal_sync = load_audio(DATA_ROOT+'audio/example_0_sync/'+str(nodes_select[i])+'_mic_0.wav')[0:(n_frames*frame_len)]\n",
    "    signals_sync[:,:,i] = np.reshape(signal_sync, (n_frames, frame_len))\n",
    "# Calculate evaluation results\n",
    "rmse_t, nodes_snr, nodes_snr_smoothed, ssnr, ssnr_async = evaluate_simulation_results(nodes_select, fs_Hz, frame_len, SRO_est, SRO_true, signals, signals_synced, signals_sync, ssnr_t_max)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reference signal and SNR values at different nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = plt.figure(); f.set_figwidth(16); f.set_figheight(3)\n",
    "plt.plot(np.arange(np.size(signals[:,:,0]))/fs_Hz, signals[:,:,0].flatten())\n",
    "plt.title('Fig.3 (a) Signal at reference node', fontsize=16)\n",
    "plt.ylim((-0.5, 0.5)); plt.xlabel('Time [s]', fontsize=16)\n",
    "plt.fill_between(np.arange(len(oracle_acs))*(frame_len/fs_Hz), oracle_acs*0.5, alpha=0.2, color='b', ec=None, label='ACS=1')\n",
    "plt.fill_between(np.arange(len(oracle_acs))*(frame_len/fs_Hz), -oracle_acs*0.5, alpha=0.2, color='b', ec=None);\n",
    "plt.legend(loc='upper left')\n",
    "\n",
    "plt.grid(); \n",
    "plt.tight_layout(); \n",
    "plt.show()\n",
    "\n",
    "nodes_snr_smoothed_mean = nodes_snr_smoothed.mean(axis=0)\n",
    "f = plt.figure(); f.set_figwidth(8); f.set_figheight(2)\n",
    "plt.bar(range(n_async_nodes+1), nodes_snr_smoothed_mean, tick_label=nodes_select)\n",
    "plt.title('Fig.3 (b) Averaged SNR at different nodes', fontsize=14)\n",
    "plt.ylabel('SNR [dB]', fontsize=14)\n",
    "plt.grid(); plt.tight_layout(); plt.show()\n",
    "print(nodes_select)\n",
    "for i in nodes_snr_smoothed_mean:\n",
    "    print('%5.2f' % i, end=' dB   ')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Resulting SRO estimation over time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "colors = ['b', 'g', 'r', 'c', 'm', 'y']\n",
    "fig, axs = plt.subplots(3, 1, figsize=(16, 6))\n",
    "\n",
    "for i in range(n_async_nodes):\n",
    "    axs[0].plot(np.arange(len(SRO_est[:,i]))*(frame_len/fs_Hz), SRO_est[:,i], label=' '.join(nodes_select[i+1].split('_')), color=colors[i%len(colors)])\n",
    "    axs[0].axhline(y=SRO_true[i], linestyle='--', color=colors[i%len(colors)], lw=1)\n",
    "axs[0].set_title('Fig.4 (a) SRO estimates', fontsize=16)\n",
    "axs[0].set_ylabel(r'$\\hat{\\varepsilon}$ [ppm]', fontsize=16)\n",
    "axs[0].set_ylim((np.min(SRO_est)-10, np.max(SRO_est)+10))    \n",
    "axs[0].grid()\n",
    "\n",
    "for i in range(n_async_nodes):\n",
    "    axs[1].plot(np.arange(len(dSRO_est[:,i]))*(frame_len/fs_Hz), dSRO_est[:,i], label=' '.join(nodes_select[i+1].split('_')), color=colors[i%len(colors)])\n",
    "axs[1].legend(loc='upper right', fontsize=12, framealpha=1)\n",
    "axs[1].set_title('Fig.4 (b) Residual SRO estimates', fontsize=16)\n",
    "axs[1].axhline(-1, linestyle='--', color='k', lw=1)\n",
    "axs[1].axhline(1, linestyle='--', color='k', lw=1)\n",
    "axs[1].set_ylabel(r'$\\Delta\\hat{\\varepsilon}$ [ppm]', fontsize=16)\n",
    "axs[1].set_ylim((-3, 3)); axs[1].grid()\n",
    "\n",
    "for i in range(n_async_nodes):\n",
    "    axs[2].plot(np.arange(len(SRO_est[:,i]))*(frame_len/fs_Hz), rmse_t[:,i], label=' '.join(nodes_select[i+1].split('_')), color=colors[i%len(colors)])\n",
    "axs[2].set_title('Fig.4 (c) RMSE values of SRO estimates', fontsize=16)\n",
    "axs[2].set_ylabel(r'$RMSE_\\varepsilon(t)$ [ppm]', fontsize=16)\n",
    "axs[2].axhline(1, linestyle='--', color='k', lw=1)\n",
    "axs[2].set_ylim((0, 3)); axs[2].grid()\n",
    "\n",
    "axs[-1].set_xlabel('Time [s]', fontsize=16)\n",
    "plt.tight_layout(); \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Synchronization performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = plt.figure(); f.set_figwidth(8); f.set_figheight(2)\n",
    "plt.bar(range(n_async_nodes), ssnr, tick_label=nodes_select[1:], label='after sync')\n",
    "plt.bar(range(n_async_nodes), ssnr_async, tick_label=nodes_select[1:], label='before sync')\n",
    "plt.title('Fig.5 Synchronization performance', fontsize=16)\n",
    "plt.ylabel('SSNR [dB]', fontsize=16)\n",
    "plt.legend()\n",
    "plt.grid(); plt.show()\n",
    "\n",
    "print(nodes_select[1:])\n",
    "for i in ssnr_async:\n",
    "    print('%5.2f' % i, end=' dB   ')\n",
    "print(' ')\n",
    "for i in ssnr:\n",
    "    print('%5.2f' % i, end=' dB   ')"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
